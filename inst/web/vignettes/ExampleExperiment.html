<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<title>Example for the usage of different algorithms on different problems</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Example for the usage of different algorithms on different problems</h1>
</div>


<div id="intro" class="section level1">
<h1>Intro</h1>
<p>We stick to a rather simple, but not unrealistic example to explain some further functionalities: Applying two classification learners to the famous iris data set (Anderson 1935), vary a few hyperparameters and evaluate the effect on the classification performance.</p>
<p>First, We create a registry, the central meta-data object which records technical details and the setup of the experiments. We use an <em>ExperimentRegistry</em> where the job definition is split into creating problems and algorithms. See the paper on <a href="http://www.jstatsoft.org/article/view/v064i11">BatchJobs and BatchExperiments</a> for a detailed explanation. Again, we use a temporary registry and make it the default registry.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(batchtools)
reg =<span class="st"> </span><span class="kw">makeTempExperimentRegistry</span>(<span class="dt">make.default =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="problems-and-algorithms" class="section level1">
<h1>Problems and algorithms</h1>
<p>By adding a problem to the registry, we can define the data on which certain computational jobs shall be done. This can be a matrix, data frame or array that always stays the same for all subsequent experiments or can be of a more dynamic nature, e.g., subsamples of a dataset or random numbers drawn from a probability distribution . Therefore the function <code>addProblem()</code> accepts static parts in its <code>data</code> argument, which is passed to the argument <code>fun</code> which generates a (possibly stochastic) problem instance. For <code>data</code>, any R object can be used. If only <code>data</code> is given, the generated instance is <code>data</code>. The argument ´fun´ has to be a function with the arguments ´data´ and ´job´ (and optionally other arbitrary parameters). The argument <code>job</code> is an object of type <code>Job</code> which holds additional information about the job (see, the manual page for a detailed listing).</p>
<p>We want to split the iris data set into a training set and test set. We use subsampling for this example which just uses a random fraction of the observations as training set. We define a problem function which returns the indices of the respective training and test set for a split with <code>ratio</code>% of the observations being in the test set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subsample =<span class="st"> </span>function(data, job, ratio, ...) {
  n =<span class="st"> </span><span class="kw">nrow</span>(data)
  train =<span class="st"> </span><span class="kw">sample</span>(n, <span class="kw">floor</span>(n *<span class="st"> </span>ratio))
  test =<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">seq</span>(n), train)
  <span class="kw">list</span>(<span class="dt">test =</span> test, <span class="dt">train =</span> train)
}</code></pre></div>
<p><code>addProblem</code> files the problem to the file system and the problem gets recorded in the registry.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;datasets&quot;</span>)
<span class="kw">addProblem</span>(<span class="dt">name =</span> <span class="st">&quot;iris&quot;</span>, <span class="dt">data =</span> iris, <span class="dt">fun =</span> subsample, <span class="dt">seed =</span> <span class="dv">42</span>)</code></pre></div>
<p>The function call will be evaluated at a later stage on the workers. In this process, the <code>data</code> part will be loaded and passed to the function. Note that we set a problem seed to synchronize the experiments in the sense that the same resampled training and test sets are used for the algorithm comparison in each distinct replication.</p>
<p>The algorithms for the jobs are added to the registry in a similar manner. When using <code>addAlgorithm()</code>, an identifying name, the registry and a function, that contains the algorithm to be applied on the problem, are required arguments. The function must have the arguments <code>job</code>, <code>data</code> and <code>instance</code>. Further arbitrary arguments (e.g., hyper-parameters or strategy parameters) may be defined analogously as for the function in <code>addProblem</code>. The objects passed to the function via <code>job</code> and <code>data</code> are here the same as above, while via <code>instance</code> the return value of the evaluated problem function is passed. The algorithm can return any R object which will automatically be stored in the file system for later retrieval. Firstly, we create a classification support vector machine:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">svm.wrapper =<span class="st"> </span>function(data, job, instance, ...) {
  <span class="kw">library</span>(<span class="st">&quot;e1071&quot;</span>)
  mod =<span class="st"> </span><span class="kw">svm</span>(Species ~<span class="st"> </span>., <span class="dt">data =</span> data[instance$train, ], ...)
  pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> data[instance$test, ], <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)
  <span class="kw">table</span>(data$Species[instance$test], pred)
}
<span class="kw">addAlgorithm</span>(<span class="dt">name =</span> <span class="st">&quot;svm&quot;</span>, <span class="dt">fun =</span> svm.wrapper)</code></pre></div>
<p>Secondly, a random forest of classification trees:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">forest.wrapper =<span class="st"> </span>function(data, job, instance, ...) {
  <span class="kw">library</span>(<span class="st">&quot;ranger&quot;</span>)
  mod =<span class="st"> </span><span class="kw">ranger</span>(Species ~<span class="st"> </span>., <span class="dt">data =</span> data[instance$train, ], <span class="dt">write.forest =</span> <span class="ot">TRUE</span>)
  pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">data =</span> data[instance$test, ])
  <span class="kw">table</span>(data$Species[instance$test], pred$predictions)
}
<span class="kw">addAlgorithm</span>(<span class="dt">name =</span> <span class="st">&quot;forest&quot;</span>, <span class="dt">fun =</span> forest.wrapper)</code></pre></div>
<p>Both algorithms return a confusion matrix for the predictions on the test set, which will later be used to calculate the misclassification rate.</p>
<p>Note that using the <code>...</code> argument in the wrapper definitions allows us to circumvent naming specific design parameters for now. This is an advantage if we later want to extend the set of algorithm parameters in the experiment. The algorithms get recorded in the registry and the corresponding functions are stored on the file system.</p>
</div>
<div id="creating-jobs" class="section level1">
<h1>Creating jobs</h1>
<p>The creation of jobs is done by adding experiments to the registry. Each experiment requires a problem design and a algorithm design which must be passed as named lists to <code>addExperiment()</code>. The elements of the lists are named after the problem or algorithm they refer to and contain a data frame or data table, in which different values for the arguments of the appropriate functions can be determined. The columns should have the same names as the arguments in order that each line defines a parameter set for the usage of the function. When the problem design and the algorithm design are combined in <code>addExperiments</code>, every combination of the parameter sets of the two designs defines a distinct job. How often each of these jobs should be computed can be determined with the argument <code>repls</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># problem design: try two values for the ratio parameter</span>
pdes =<span class="st"> </span><span class="kw">list</span>(<span class="dt">iris =</span> <span class="kw">data.frame</span>(<span class="dt">ratio =</span> <span class="kw">c</span>(<span class="fl">0.67</span>, <span class="fl">0.9</span>)))

<span class="co"># algorithm design: try combinations of kernel and epsilon exhaustively,</span>
<span class="co"># try different number of trees for the forest</span>
ades =<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">svm =</span> <span class="kw">expand.grid</span>(<span class="dt">kernel =</span> <span class="kw">c</span>(<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;polynomial&quot;</span>, <span class="st">&quot;radial&quot;</span>), <span class="dt">epsilon =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>)),
  <span class="dt">forest =</span> <span class="kw">data.frame</span>(<span class="dt">ntree =</span> <span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>))
)

<span class="kw">addExperiments</span>(pdes, ades, <span class="dt">repls =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>## Adding 60 experiments ('iris'[2] x 'svm'[6] x repls[5]) ...
## Adding 30 experiments ('iris'[2] x 'forest'[3] x repls[5]) ...</code></pre>
<p>The jobs are now available in the registry with an individual ID for each. The function <code>summarizeExperiments()</code> returns a table which gives a quick overview over all defined experiments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summarizeExperiments</span>()</code></pre></div>
<pre><code>##    problem algorithm .count
## 1:    iris       svm     60
## 2:    iris    forest     30</code></pre>
<p>Before submitting all jobs to the batch system, we encourage you to test each algorithm individually. Or sometimes you want to submit only a subset of experiments because the jobs vastly differ in runtime. Another reoccurring task is the collection of results for only a subset of experiments. For all these use cases, <code>findExperiments()</code> can be employed to conveniently select a particular subset of jobs. It returns the IDs of all experiments that match the given criteria. Your selection can depend on substring matches of problem or algorithm IDs using <code>prob.name</code> or <code>algo.name</code>, respectively. You can also pass R expressions, which will be evaluated in your problem parameter setting (<code>prob.pars</code>) or algorithm parameter setting (<code>algo.pars</code>). The expression is then expected to evaluate to a Boolean value. Furthermore, you can restrict the experiments to specific replication numbers.</p>
<p>To illustrate <code>findExperiments()</code>, we will select two experiments, one with a support vector machine and the other with a random forest and the parameter <code>ntree = 1000</code>. The selected experiment IDs are then passed to testJob.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">id1 =<span class="st"> </span><span class="kw">findExperiments</span>(<span class="dt">algo.name =</span> <span class="st">&quot;svm&quot;</span>)[<span class="dv">1</span>]
id2 =<span class="st"> </span><span class="kw">findExperiments</span>(<span class="dt">algo.name =</span> <span class="st">&quot;forest&quot;</span>, <span class="dt">algo.pars =</span> (ntree ==<span class="st"> </span><span class="dv">1000</span>))[<span class="dv">1</span>]
<span class="kw">testJob</span>(<span class="dt">id =</span> id1)</code></pre></div>
<pre><code>## Generating problem instance for problem iris ...
## Applying algorithm svm on problem iris ...</code></pre>
<pre><code>##             pred
##              setosa versicolor virginica
##   setosa         17          0         0
##   versicolor      0         16         2
##   virginica       0          0        15</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">testJob</span>(<span class="dt">id =</span> id2)</code></pre></div>
<pre><code>## Generating problem instance for problem iris ...
## Applying algorithm forest on problem iris ...</code></pre>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         17          0         0
##   versicolor      0         16         2
##   virginica       0          0        15</code></pre>
<p>After the jobs are executed, we collect the results with <code>reduceResultsDataTable()</code> and directly extract the mean misclassification error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">submitJobs</span>()</code></pre></div>
<pre><code>## Submitting 90 jobs in 90 chunks using cluster functions 'Interactive' ...
## Syncing 90 files ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results =<span class="st"> </span><span class="kw">reduceResultsDataTable</span>(<span class="dt">fun =</span> function(res) (<span class="kw">list</span>(<span class="dt">mce =</span> (<span class="kw">sum</span>(res) -<span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(res))) /<span class="st"> </span><span class="kw">sum</span>(res))))</code></pre></div>
<p>Next, we merge the results table with the table of job parameters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tab =<span class="st"> </span><span class="kw">merge</span>(<span class="kw">getJobPars</span>(), results)
<span class="kw">print</span>(<span class="kw">head</span>(tab))</code></pre></div>
<pre><code>##    job.id problem algorithm ratio     kernel epsilon ntree  mce
## 1:      1    iris       svm  0.67     linear    0.01    NA 0.04
## 2:      2    iris       svm  0.67     linear    0.01    NA 0.04
## 3:      3    iris       svm  0.67     linear    0.01    NA 0.04
## 4:      4    iris       svm  0.67     linear    0.01    NA 0.04
## 5:      5    iris       svm  0.67     linear    0.01    NA 0.04
## 6:      6    iris       svm  0.67 polynomial    0.01    NA 0.06</code></pre>
<p>We now use <code>data.table</code> to aggregate the results per group. If you prefer, you can also use <code>base::aggregate()</code> or function from the <code>dplyr</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tab[ratio ==<span class="st"> </span><span class="fl">0.67</span>, <span class="kw">list</span>(<span class="dt">mmce =</span> <span class="kw">mean</span>(mce)), by =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;algorithm&quot;</span>, <span class="st">&quot;kernel&quot;</span>, <span class="st">&quot;epsilon&quot;</span>, <span class="st">&quot;ntree&quot;</span>)]</code></pre></div>
<pre><code>##    algorithm     kernel epsilon ntree  mmce
## 1:       svm     linear    0.01    NA 0.040
## 2:       svm polynomial    0.01    NA 0.060
## 3:       svm     radial    0.01    NA 0.060
## 4:       svm     linear    0.10    NA 0.040
## 5:       svm polynomial    0.10    NA 0.060
## 6:       svm     radial    0.10    NA 0.060
## 7:    forest         NA      NA   100 0.048
## 8:    forest         NA      NA   500 0.056
## 9:    forest         NA      NA  1000 0.048</code></pre>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
