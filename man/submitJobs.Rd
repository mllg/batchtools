% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/submitJobs.R
\name{submitJobs}
\alias{submitJobs}
\title{Submit Jobs to the Batch Systems}
\usage{
submitJobs(ids = NULL, resources = list(), reg = getDefaultRegistry())
}
\arguments{
\item{ids}{[\code{\link[base]{data.frame}} or \code{integer}]\cr
A \code{\link[base]{data.frame}} (or \code{\link[data.table]{data.table}})
with a column named \dQuote{job.id}.
Alternatively, you may also pass a vector of integerish job ids.
If not set, defaults to the return value of \code{\link{findNotSubmitted}}.}

\item{resources}{[\code{named list}]\cr
Computational  resources for the batch jobs. The elements of this list
(e.g. something like \dQuote{walltime} or \dQuote{nodes}) depend on your template file.
See notes for reserved special resource names.
Defaults can be set in the \code{\link{Registry}} via the variable \code{default.resources} as a named list.
The setting can be made permanent for all future registries by setting this variable in your configuration file.
Individual settings set via \code{resources} \code{resources} overrule those in \code{default.resources}.}

\item{reg}{[\code{\link{Registry}}]\cr
Registry. If not explicitly passed, uses the last created registry.}
}
\value{
[\code{\link{data.table}}]. Table with columns \dQuote{job.id} and \dQuote{chunk}.
  See \code{\link{JoinTables}} for examples on working with job tables.
}
\description{
Submits all jobs defined with \code{\link{batchMap}} to the batch system.

If an additional column \dQuote{chunk} is present in the table \code{ids},
the jobs will be grouped accordingly. See \code{\link{chunkIds}} for more
information.

After submitting the jobs, you can use \code{\link{waitForJobs}} to wait for the
termination of jobs or immediately call \code{\link{reduceResultsList}}/\code{\link{reduceResults}}
to collect partial results.
The progress can be monitored with \code{\link{getJobStatus}}.
}
\note{
Setting the resource \code{measure.memory} to \code{TRUE} turns on memory measurement:
\code{\link[base]{gc}} is called  directly before
and after the job and the difference is stored in the internal database. Note that this is just a rough estimate and does
neither work reliably for external code like C/C++ nor in combination with threading.

Furthermore, the package provides support for inner parallelization using threading, sockets or MPI via the
package \pkg{parallelMap}.
If you set the resource \dQuote{pm.backend} to \dQuote{multicore}, \dQuote{socket} or \dQuote{mpi},
\code{\link[parallelMap]{parallelStart}} is called on the slave before the first job in the chunk is started
and \code{\link[parallelMap]{parallelStop}} is called after the last job terminated.
This way, the used resources for inner parallelization are set in the same place as the resources for the outer parallelization and
get automatically stored in the \code{\link{Registry}}.
The user function just has to call \code{\link[parallelMap]{parallelMap}} to start parallelization to use the configured backend.

You may set the resource \code{ncpus} to control the number of CPUs to use in \pkg{parallelMap}.
\code{ncpus} defaults to the number of available CPUs (as reported by (see \code{\link[parallel]{detectCores}}))
on the executing machine for multicore and socket mode and defaults to the return value of \code{\link[Rmpi]{mpi.universe.size}-1} for MPI.
You can pass further options like \code{level} to \code{\link[parallelMap]{parallelStart}} via the named list \dQuote{pm.opts}.

Note that your template must be set up to handle the parallelization, e.g. start R with \code{mpirun} or request the correct number of CPUs.

Also note that if you have thousands of jobs, disabling the progress bar (\code{options(batchtools.progress = FALSE)})
can significantly increase the performance.
}
\examples{
### Example 1: Using memory measurement
reg = makeRegistry(file.dir = NA, make.default = FALSE)

# Toy function which creates a large matrix and returns the column sums
fun = function(n, p) colMeans(matrix(runif(n*p), n, p))

# Arguments to fun:
args = expand.grid(n = c(1e4, 1e5), p = c(10, 50))
print(args)

# Map function to create jobs
ids = batchMap(fun, args = args, reg = reg)

# Set resources: enable memory measurement
res = list(measure.memory = TRUE)

# Submit jobs using the currently configured cluster functions
submitJobs(ids, resources = res, reg = reg)

# Retrive information about memory, combine with parameters
info = ijoin(getJobStatus(reg = reg)[, .(job.id, memory)], getJobPars(reg = reg))
print(info)

# Combine job info with results -> each job is aggregated using mean()
ijoin(info, reduceResultsDataTable(fun = function(res) list(res = mean(res)), reg = reg))

\dontrun{
### Example 2: Multicore execution on the slave
reg = makeRegistry(file.dir = NA, make.default = FALSE)

# Function which sleeps 10 seconds, i-times
f = function(i) {
  parallelMap::parallelMap(Sys.sleep, rep(10, i))
}

# Create one job with parameter i=4
ids = batchMap(f, i = 4, reg = reg)

# Set resources: Use parallelMap in multicore mode with 4 CPUs
# batchtools internally loads the namespace of parallelMap and then calls parallelStart() before the job and
# parallelStop() right after the job terminated.
res = list(pm.backend = "multicore", ncpus = 4)

# Submit both jobs and wait for them
submitJobs(resources = res, reg = reg)
waitForJobs(reg = reg)

# If successfull, the running time should be ~10s
getJobTable(reg = reg)[, .(job.id, time.running)]

# There should also be a note in the log:
grepLogs(pattern = "parallelMap", reg = reg)
}
}

